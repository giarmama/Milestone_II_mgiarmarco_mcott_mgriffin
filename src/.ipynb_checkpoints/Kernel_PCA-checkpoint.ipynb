{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0c6d8b3",
   "metadata": {},
   "source": [
    "# Milestone II PCA Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947109e5",
   "metadata": {},
   "source": [
    "### Primary Component Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ae7bc91-aff0-4020-94e9-7e4857f06a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import TruncatedSVD, PCA, KernelPCA\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37c1b380-af8d-4d1d-9fc7-139bf44e24c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/final_cleaned.csv', dtype={1: str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe4a29ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 264. GiB for an array with shape (188117, 188117) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 34\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m#X_final = X_final.sample(100)\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Run PCA\u001b[39;00m\n\u001b[0;32m     33\u001b[0m Kpca \u001b[38;5;241m=\u001b[39m KernelPCA(n_components\u001b[38;5;241m=\u001b[39mn_components)\n\u001b[1;32m---> 34\u001b[0m X_train_pca \u001b[38;5;241m=\u001b[39m Kpca\u001b[38;5;241m.\u001b[39mfit_transform(X_final)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Get eigenvalues for features, set up for feature importance\u001b[39;00m\n\u001b[0;32m     37\u001b[0m eigenvalues \u001b[38;5;241m=\u001b[39m Kpca\u001b[38;5;241m.\u001b[39meigenvalues_\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    301\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:472\u001b[0m, in \u001b[0;36mKernelPCA.fit_transform\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[0;32m    452\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model from data in X and transform X.\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \n\u001b[0;32m    454\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;124;03m        Returns the instance itself.\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 472\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    474\u001b[0m     \u001b[38;5;66;03m# no need to use the kernel to transform X, use shortcut expression\u001b[39;00m\n\u001b[0;32m    475\u001b[0m     X_transformed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meigenvectors_ \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meigenvalues_)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:439\u001b[0m, in \u001b[0;36mKernelPCA.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_centerer \u001b[38;5;241m=\u001b[39m KernelCenterer()\u001b[38;5;241m.\u001b[39mset_output(transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 439\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_kernel(X)\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_transform(K)\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_inverse_transform:\n\u001b[0;32m    443\u001b[0m     \u001b[38;5;66;03m# no need to use the kernel to transform X, use shortcut expression\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\decomposition\\_kernel_pca.py:320\u001b[0m, in \u001b[0;36mKernelPCA._get_kernel\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma_, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdegree\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdegree, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoef0\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef0}\n\u001b[1;32m--> 320\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pairwise_kernels(\n\u001b[0;32m    321\u001b[0m     X, Y, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel, filter_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    322\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2522\u001b[0m, in \u001b[0;36mpairwise_kernels\u001b[1;34m(X, Y, metric, filter_params, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   2519\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(metric):\n\u001b[0;32m   2520\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(_pairwise_callable, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m-> 2522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:1871\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1868\u001b[0m X, Y, dtype \u001b[38;5;241m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1871\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(X, Y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1873\u001b[0m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[0;32m   1874\u001b[0m fd \u001b[38;5;241m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:1364\u001b[0m, in \u001b[0;36mlinear_kernel\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;124;03mCompute the linear kernel between X and Y.\u001b[39;00m\n\u001b[0;32m   1332\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1361\u001b[0m \u001b[38;5;124;03m       [1., 2.]])\u001b[39;00m\n\u001b[0;32m   1362\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1363\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m check_pairwise_arrays(X, Y)\n\u001b[1;32m-> 1364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m safe_sparse_dot(X, Y\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39mdense_output)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:208\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    206\u001b[0m         ret \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(a, b)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m     ret \u001b[38;5;241m=\u001b[39m a \u001b[38;5;241m@\u001b[39m b\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    211\u001b[0m     sparse\u001b[38;5;241m.\u001b[39missparse(a)\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    215\u001b[0m ):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 264. GiB for an array with shape (188117, 188117) and data type float64"
     ]
    }
   ],
   "source": [
    "n_components = 10\n",
    "states = ['CHI', 'NYC']\n",
    "results = {}\n",
    "\n",
    "for state in states:\n",
    "    # Check each state individually\n",
    "    df_state = data[data['state'] == state].copy().dropna().reset_index(drop=True)\n",
    "\n",
    "    # Define columns\n",
    "    exclude_cols = ['date', 'state', 'daily_ridership', 'unit_id', 'mode']\n",
    "    feature_cols = [col for col in df_state.columns if col not in exclude_cols]\n",
    "\n",
    "    # Truncated SVD on unit_id\n",
    "    ohe_unit = OneHotEncoder(sparse_output=True, handle_unknown='ignore')\n",
    "    unit_sparse = ohe_unit.fit_transform(df_state[['unit_id']])\n",
    "    svd = TruncatedSVD(n_components=20, random_state=42)\n",
    "    unit_svd = svd.fit_transform(unit_sparse)\n",
    "    unit_svd_df = pd.DataFrame(unit_svd, index=df_state.index, columns=[f'unit_svd_{i+1}' for i in range(20)])\n",
    "\n",
    "    # One-hot encode mode\n",
    "    mode_dummies = pd.get_dummies(df_state['mode'], prefix='mode', drop_first=True)\n",
    "\n",
    "    # Scale weather + AQI features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(df_state[feature_cols])\n",
    "    scaled_df = pd.DataFrame(X_scaled, index=df_state.index, columns=feature_cols)\n",
    "\n",
    "    # Combine unit SVD, one-hot, and scaled features\n",
    "    X_final = pd.concat([unit_svd_df, mode_dummies.reset_index(drop=True), scaled_df], axis=1)\n",
    "    #X_final = X_final.sample(100)\n",
    "    \n",
    "    # Run PCA\n",
    "    Kpca = KernelPCA(n_components=n_components)\n",
    "    X_train_pca = Kpca.fit_transform(X_final)\n",
    "\n",
    "    \n",
    "    # Get eigenvalues for features, set up for feature importance\n",
    "    eigenvalues = Kpca.eigenvalues_\n",
    "    feature_loadings = np.zeros((X_final.shape[1], n_components))\n",
    "    \n",
    "    # Get correlations for each component\n",
    "    for i in range(n_components):\n",
    "        pc_values = X_train_pca[:,i]\n",
    "        for j, feature_name in enumerate(X_final.columns):\n",
    "            feature_values = X_final.iloc[:,j].values\n",
    "            correlation = np.corrcoef(pc_values, feature_values)[0,1]\n",
    "            feature_loadings[j, i] = correlation if not np.isnan(correlation) else 0\n",
    "    \n",
    "    # Get top features, create df with them\n",
    "    feature_importance_scores = np.sum(np.abs(feature_loadings), axis=1)\n",
    "\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'feature': X_final.columns,\n",
    "        'importance_score': feature_importance_scores\n",
    "    }).sort_values('importance_score', ascending=False)\n",
    "    \n",
    "    top_features = feature_importance_df\n",
    "    \n",
    "    # Add individual component loadings to top features\n",
    "    loading_cols = [f'PC{i+1}_loading' for i in range(n_components)]\n",
    "    for i, col in enumerate(loading_cols):\n",
    "        top_features[col] = [feature_loadings[X_final.columns.get_loc(feat), i] \n",
    "                            for feat in top_features['feature']]\n",
    "\n",
    "    top_features.to_csv(\"top_features.csv\", index=False)\n",
    "    \n",
    "    print(\"Kernel PCA Results:\")\n",
    "    print(f\"Eigenvalues: {eigenvalues}\")\n",
    "    print(f\"\\nTop {top_features} features:\")\n",
    "    print(top_features.to_string(index=False))\n",
    "\n",
    "\n",
    "    # Save PCA transformed data and model output\n",
    "    joblib.dump(X_train_pca, \"X_train_pca.pkl\")\n",
    "    joblib.dump(kpca.eigenvalues_, \"eigenvalues.pkl\")\n",
    "    joblib.dump(feature_loadings, \"feature_loadings.pkl\")\n",
    "    feature_importance_df.to_csv(\"top_features.csv\", index=False)\n",
    "\n",
    "    results = (X_train_pca, eigenvalues, top_features, feature_loadings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31c19b6-d7f1-4f7d-b360-3a83e512a72b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
